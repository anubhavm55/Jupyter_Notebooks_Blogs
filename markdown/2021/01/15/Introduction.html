<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Introduction to deep learning(3rd Semester) | Learning Deep Learning</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Introduction to deep learning(3rd Semester)" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="My introduction to Deep Learning." />
<meta property="og:description" content="My introduction to Deep Learning." />
<link rel="canonical" href="https://anubhavm55.github.io/Jupyter_Notebooks_Blogs/markdown/2021/01/15/Introduction.html" />
<meta property="og:url" content="https://anubhavm55.github.io/Jupyter_Notebooks_Blogs/markdown/2021/01/15/Introduction.html" />
<meta property="og:site_name" content="Learning Deep Learning" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-01-15T00:00:00-06:00" />
<script type="application/ld+json">
{"url":"https://anubhavm55.github.io/Jupyter_Notebooks_Blogs/markdown/2021/01/15/Introduction.html","@type":"BlogPosting","headline":"Introduction to deep learning(3rd Semester)","dateModified":"2021-01-15T00:00:00-06:00","datePublished":"2021-01-15T00:00:00-06:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://anubhavm55.github.io/Jupyter_Notebooks_Blogs/markdown/2021/01/15/Introduction.html"},"description":"My introduction to Deep Learning.","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/Jupyter_Notebooks_Blogs/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://anubhavm55.github.io/Jupyter_Notebooks_Blogs/feed.xml" title="Learning Deep Learning" /><link rel="shortcut icon" type="image/x-icon" href="https://raw.githubusercontent.com/anubhavm55/Jupyter_Notebooks_Blogs/master/images/favicon.ico">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/Jupyter_Notebooks_Blogs/">Learning Deep Learning</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/Jupyter_Notebooks_Blogs/about/">About Me</a><a class="page-link" href="/Jupyter_Notebooks_Blogs/search/">Search</a><a class="page-link" href="/Jupyter_Notebooks_Blogs/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Introduction to deep learning(3rd Semester)</h1><p class="page-description">My introduction to Deep Learning.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2021-01-15T00:00:00-06:00" itemprop="datePublished">
        Jan 15, 2021
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      4 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/Jupyter_Notebooks_Blogs/categories/#markdown">markdown</a>
        
      
      </p>
    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p>Recently I came across a deep learning course that has changed my life forever!!! I am talking about fast.ai’s <a href="https://fast.ai">FastAI</a> “Practical Deep Learning for Coders”. I was looking for a course that could explain the “coding” part of deep learning. One of my friend suggested MITs <a href="https://introtodeeplearning.com">“Introduction to deep learning”</a>, its nice but could have been nicer if the code in lab part was also explained. FastAI does that and I call it my spirit course.</p>

<h2 id="first-misunderstanding-deep-learning-only-for-phds">First misunderstanding: Deep Learning only for PhDs</h2>

<p>I started deep learning in my 3rd semester minor project(currently in 6th semester) and I went through a lot of courses on youtube and coursera. At first, it was very exciting to know the maths behind all of this but when I tried to implement it I was unable to do so. I found myself searching tutorials and guides for tensorflow, keras, pytorch but nothing made sense. I was frustrated as I was unable to implement something which I understood. For example, the project that I was working on had the equation for the prediction as<br />
y(m,t) = Σσ<sub>1</sub>(b+m*e<sup>w1</sup>) * σ<sub>2</sub>(b-t*e<sup>w2</sup>) * e<sup>w3</sup><br />
where σ<sub>1</sub> is softplus function and σ<sub>2</sub> is a sigmoid function.<br />
The above equation clearly states that I have to create all these layers from scratch since all the predefined models do computation of the form b+(some input)*w. Making above architecture seemed so difficult to me and I came to the conclusion that only PhDs understood intricacies of deep learning. So, at last I went to tensorflow keras tutorial, randomly added lots of dense and embedding(lol, it didn’t require any embedding layer, I didn’t even know back then what an embedding layer was) layers for this model, got an accuracy so bad(mape of 1 lakh) and lost all interest in deep learning.<br />
For those who are looking for the code to implement above architecture:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="k">class</span> <span class="nc">DenseLayer1</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Layer</span><span class="p">):</span>
  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_output_nodes</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">DenseLayer1</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">n_output_nodes</span><span class="o">=</span><span class="n">n_output_nodes</span>

  <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">W</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">add_weight</span><span class="p">(</span><span class="s">"weight"</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">n_output_nodes</span><span class="p">])</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">b</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">add_weight</span><span class="p">(</span><span class="s">"bias"</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">n_output_nodes</span><span class="p">])</span> 

  <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">b</span> <span class="o">-</span> <span class="n">x</span><span class="o">*</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">math</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">W</span><span class="p">))</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">math</span><span class="p">.</span><span class="n">softplus</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">y</span>
    
  <span class="k">class</span> <span class="nc">DenseLayer2</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Layer</span><span class="p">):</span>
  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_output_nodes</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">DenseLayer2</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">n_output_nodes</span><span class="o">=</span><span class="n">n_output_nodes</span>

  <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">W</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">add_weight</span><span class="p">(</span><span class="s">"weight"</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">n_output_nodes</span><span class="p">])</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">b</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">add_weight</span><span class="p">(</span><span class="s">"bias"</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">n_output_nodes</span><span class="p">])</span> 

  <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">b</span> <span class="o">+</span> <span class="n">x</span><span class="o">*</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">math</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">W</span><span class="p">))</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">y</span>
    
  <span class="k">class</span> <span class="nc">DenseLayer3</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Layer</span><span class="p">):</span>
  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_output_nodes</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">DenseLayer3</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">n_output_nodes</span><span class="o">=</span><span class="n">n_output_nodes</span>

  <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">W</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">add_weight</span><span class="p">(</span><span class="s">"weight"</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">n_output_nodes</span><span class="p">])</span>

  <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">*</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">math</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">W</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">tf</span><span class="p">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<p>Let me explain how easy it is to implement above architecture which seemed like a gigantic task back then. I am doing tensorflow because currently I am enrolled in a deep learning course in my college which is taught in tensorflow, but it doesn’t matter, the difference is only in the syntax and one can easily convert to pytorch in a week or so.</p>

<p>In tensorflow, every layer is a defined as a class and the first function is same for all of the 3 layers which defines the number of neurons in that respective layer, a parameter that you have to pass in the variable n_output_nodes. Second function is also same, randomly initializes weights and biases. The shape of these values can change depending on your data. For our case, we require only one weight for one input and we have n_output_nodes neurons so shape is defined like that. If, on the other hand we had images as inputs then for one input(one image) we may keep weights for each of the pixels in the image, therefore we would have defined the shape as [no. of pixels, n_out_nodes]. For those who do not understand this, what we generally do is convert image into 2d matrix and then convert it to 1d array by keeping all the values from the matrix contiguously for easy computation. Then the third function, which defines what function we want to apply to inputs and parameters(other name for weights and biases combined). You can perform operations on these custom layers now as you perform on predefined layers. That is it, that is what I had to do back then, if only I found a course which explained the coding part rather than the math part.</p>

<h2 id="second-misunderstanding-more-epochs-means-more-accuracy">Second misunderstanding: More epochs means more accuracy</h2>
<p>I remember I used to train the above model for 250 epochs and leave my laptop for hours thinking that the error would decrease. Back then I thought that infinite epochs could make a perfect 100% accurate model. After taking the fast.ai course, I’ve come across exceptional accuracy by training for only 3 epochs. That is why 250 seems a very large number.</p>

<p>So that was my introduction to deep learning which was not very pleasant as evident.</p>


  </div><a class="u-url" href="/Jupyter_Notebooks_Blogs/markdown/2021/01/15/Introduction.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/Jupyter_Notebooks_Blogs/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/Jupyter_Notebooks_Blogs/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/Jupyter_Notebooks_Blogs/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>This is my journey in trying to make sense of deep learning.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/anubhavm55" title="anubhavm55"><svg class="svg-icon grey"><use xlink:href="/Jupyter_Notebooks_Blogs/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/anubhavm55" title="anubhavm55"><svg class="svg-icon grey"><use xlink:href="/Jupyter_Notebooks_Blogs/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
